{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malaria-dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohansivasai/Malaria-Cell-Images/blob/master/Malaria-cell-dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXxCSuwMmJlU",
        "colab_type": "code",
        "outputId": "29710033-0cc2-4a2f-86bf-b565acb81832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import the dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,BatchNormalization,Dense\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW-RP8kxut2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kaggle file configurations\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEqXOc_Uu4JR",
        "colab_type": "code",
        "outputId": "e42bf05a-5888-4ab7-aa21-983e8fe4c8dc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf867c47-e130-4a20-a271-aad725d41592\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cf867c47-e130-4a20-a271-aad725d41592\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mohansivasai12\",\"key\":\"6fb9013379729ec6afb9a93c01e54665\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqS1jVudvAGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKUade8mvLTN",
        "colab_type": "code",
        "outputId": "9c2c3861-d19f-4462-865c-a51665ea7cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading cell-images-for-detecting-malaria.zip to /content\n",
            " 98% 665M/675M [00:26<00:00, 30.3MB/s]\n",
            "100% 675M/675M [00:26<00:00, 26.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VQ4TxY-vQ0I",
        "colab_type": "code",
        "outputId": "008ea1b8-f72e-430c-a6df-701becc5a350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cell-images-for-detecting-malaria.zip  kaggle.json  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8doH-LRFCykt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzipping the file\n",
        "import zipfile\n",
        "local_zip = '/content/cell-images-for-detecting-malaria.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJBbDd3YEF0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parasite_dir = os.path.join('/content/cell_images/cell_images/Parasitized')\n",
        "uninfected_dir = os.path.join('/content/cell_images/cell_images/Uninfected')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H9Navh8FcY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(parasite_dir))\n",
        "uninfected_img = os.listdir(uninfected_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmve9CSsF84o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spliting the data into training and validation \n",
        "try:\n",
        "  os.mkdir('/content/train/')\n",
        "  os.mkdir('/content/test/')\n",
        "  os.mkdir('/content/train/Parasitized')\n",
        "  os.mkdir('/content/train/Uninfected')\n",
        "  os.mkdir('/content/test/Parasitized')\n",
        "  os.mkdir('/content/test/Uninfected')\n",
        "except OSError:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy571Jn8JSY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOOPB6IBJad1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data(source,train,test,split_size = 0.65):\n",
        "  files = list(os.listdir(source))\n",
        "  #print(files)\n",
        "  train_len = int(len(files)*split_size)\n",
        "  test_len = int(len(files)*(1-split_size))\n",
        "  shuffled_list = random.sample(files,len(files))\n",
        "  train_set = shuffled_list[:train_len]\n",
        "  #print(train_set[:10])\n",
        "  test_set  = shuffled_list[-test_len:]\n",
        "  #print(len(test_set))\n",
        "  for filename in train_set:\n",
        "    #print(filename)\n",
        "    sor =  source+filename\n",
        "    dest = train + filename\n",
        "    copyfile(sor,dest)\n",
        "  for filename in test_set:\n",
        "    #print(filename)\n",
        "    sor = source + filename \n",
        "    dest = test + filename\n",
        "    copyfile(sor,dest)\n",
        "\n",
        "\n",
        "parasite_source = '/content/cell_images/Parasitized/'\n",
        "train_para_dir  = '/content/train/Parasitized/'\n",
        "test_para_dir = '/content/test/Parasitized/'\n",
        "uninfected_source = '/content/cell_images/Uninfected/'\n",
        "train_uninfect_dir = '/content/train/Uninfected/'\n",
        "test_uninfect_dir = '/content/test/Uninfected/'\n",
        "\n",
        "split_data(parasite_source,train_para_dir,test_para_dir)\n",
        "split_data(uninfected_source,train_uninfect_dir,test_uninfect_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpAVXa9zjQdE",
        "colab_type": "code",
        "outputId": "6438ddc3-4a03-4054-a68a-301b11650278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(os.listdir('/content/train/Parasitized')))\n",
        "print(len(os.listdir('/content/train/Uninfected')))\n",
        "print(len(os.listdir('/content/test/Parasitized')))\n",
        "print(len(os.listdir('/content/test/Uninfected')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11024\n",
            "11024\n",
            "2755\n",
            "2755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkI-slO4l2Ix",
        "colab_type": "code",
        "outputId": "d9a7893b-afeb-4645-c20c-cda7eb773f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#using image data generator\n",
        "train_dir = '/content/train'\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=30,horizontal_flip=True,vertical_flip=True,fill_mode='nearest')\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "val_dir = '/content/test'\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255,horizontal_flip=True,vertical_flip=True,fill_mode = 'nearest')\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size = (224,224),\n",
        "    batch_size  = 32,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22046 images belonging to 2 classes.\n",
            "Found 5510 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxbGE73SSD9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using Resnet-50 model\n",
        "input_shape = (224,224,3)\n",
        "resnet = ResNet50(input_shape = input_shape,\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucuxj2zeS2gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in resnet.layers:\n",
        "  layer.trainable  = False\n",
        "resnet.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTTUwoT6TJ7B",
        "colab_type": "code",
        "outputId": "f30e08b9-419a-4a33-82de-a5f7f62f7daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = layers.Dropout(0.5)(resnet.output)\n",
        "x = layers.Flatten()(x)\n",
        "#x = layers.Dense(1024,activation = 'relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(256,activation = 'relu')(x)\n",
        "pred = layers.Dense(1,activation = 'sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = resnet.input,outputs = pred)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 2048)   0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 100352)       0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 100352)       0           flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 256)          25690368    dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            257         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 49,278,337\n",
            "Trainable params: 25,690,625\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u36rMu-V_GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV3BdAT6YEqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callbacks\n",
        "class MyCall(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs = {}):\n",
        "    if (logs.get('acc') > 0.9) and (logs.get('val_acc')>0.85):\n",
        "      print('\\n Reached the desired accuracy so stopping the training')\n",
        "      self.model.stop_training = True\n",
        "callback = MyCall()\n",
        "#lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch:10**-8 * 10**(epoch/20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qda-GcEZ-Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training the model\n",
        "hist = model.fit(\n",
        "    train_gen,\n",
        "    epochs = 10,\n",
        "    validation_data = val_gen,\n",
        "    verbose = 1,\n",
        "    callbacks = [callback]#,lr_schedule]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hCqeKDAbDnN",
        "colab_type": "code",
        "outputId": "021a05e1-0f60-4e5a-dada-bb727faab14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "#plot the model\n",
        "acc = hist.history['acc']\n",
        "loss = hist.history['loss']\n",
        "val_acc = hist.history['val_acc']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs,acc,'r')\n",
        "plt.plot(epochs,val_acc,'b')\n",
        "plt.legend()\n",
        "plt.title('Training Accuracy Vs Validation accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'r')\n",
        "plt.plot(epochs,val_loss,'b')\n",
        "plt.legend()\n",
        "plt.title('Training Loss Vs Validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAfI0lEQVR4nO3de5gcVbnv8e8vFwiQkMQkICaBBAko\nICKOoCIIIltQBEEPwgYE9wbcSgDxint7YfN42eccHxXckYsod7mLZisHFOQiKpIJIBouIaKQCREm\nITfA3Mh7/ljVTk2nZ6ZnmJrKTP0+z1PPdNVaXf129fR6q9aqrlJEYGZm1TWs7ADMzKxcTgRmZhXn\nRGBmVnFOBGZmFedEYGZWcU4EZmYV50QwiEgaLukFSdv3Z13b9Ek6WdJd2eNuP9t83T6+1i8kHdfX\n59vg40RQoOzLWps2SPp7br7XX7SIeDkiRkfE0/1Zt6+yBickfbCo1yiTpC9K+lWD5dtKWifpdU2u\nZ0tJKyXt36Dsu5Ku7U1c/fnZSvqqpMvq1v9PEXH1K123DR5OBAXKvqyjI2I08DTw/tyyjb5okkYM\nfJSvyInA88BHBvqFJQ0fgJe5Ethf0tS65ccCD0TEY82sJCJeAm6gbjtJGgkcA1zeD7FaDwbh92vA\nOBGUKNsbu07SNZJWAcdLepuk+yQtl7RY0vlZg4GkEdke+LRs/qqs/P9JWiXpd5Km97ZuVn6opPmS\nVmR7qb+RdFI3sb8W2Bc4FThU0qS68qMkPZTtCS+Q9E/Z8gmSLsve2zJJN2XLO3VndBH/LEm3SnoR\n2E/S4bnXeFrSl+pi2D/bliskLZR0QrZ9n5E0LFfvaElz699jRDwF3AOcUFf0EeCK7Lk7S7one40l\nkn7UxSa7HPiQpFG5ZYcC64FfZOv6oqQns89nnqTDG62owbaZJOln2Xa4D5heV/+/JbVl5XMkvT1b\nfhjwOeC47Ch1brb83tpnL2mYpC9LekrSc9lnt3VWtlMWx0ey9bdLOruL909fPq9s+ZaSvp09Z0W2\nvTeX9G5Jf61bR5ukA7LHvfp+Zc95g6TbJT0v6W+SPidpsqSXJI3L1ds7Kx8aySUiPA3ABPwVeHfd\nsq8Ca4H3k5LyFsBbgH2AEcCOwHxgZlZ/BBDAtGz+KmAJ0AKMBK4DrupD3W2AVcARWdmngHXASd28\nn/8Efps9fhQ4M1f2dmA5cFD2vqYCu2RltwE/AsZnr7V/tvxk4K7cOhrFvwx4W7bOzYF3Abtl82/M\n3t9hWf3pwAvA0dm6JgJ7ZmWPAwfnXut/8vHXvc8TgUdz87sBa4BXZfM3AJ/PYhgF7NvFegQ8CRyT\nW3YD8M3c/NHAdtm6/jmLf9v67dNg29wIXANsCewBLK7blicAr8qe93lgEbB57n/wsrpY76199qRE\nPz/bnmOAnwKXZmU7ZXFcmL33vbJtM6OLbdDXz+si4I5s2wwH3pH977wb+Gvda7QBB/Tx+zUWeBY4\nk/T/tTWwd1b2C+CU3Ot8F/h22e1Kv7VPZQdQlYmuE8GvenjeZ4AbsseNGscLc3UPB/7Uh7r/Avw6\nV6asMTmpi5gE/CX3BfoSMDdX/gPg/zZ43lTSHvDYBmXNJIIf9rCt/rv2ullMN3RR7z+Ay7PHE4GX\ngG26qDs6a6BqDcL/Bm7Klf8IuACY3MT/wDnALdnjccBq4A3d1P8T8L767ZPfNqQGcT2wU+55/ye/\nLRt8dquA3XL/g5fV1ckngruBU3NltUQ4jI5E8Opc+QPAh5r8TvT4eZEa/jW1eOvKmkkEvfl+nQDM\n6aLeccDdue3fDuzVzPscDJO7hsq3MD8j6XWSfp4ddq4EziU1Vl35W+7xS6SGq7d1X5OPI9J/e1s3\n69kfmEI6qoDUGO4lafdsfirw5wbPmwosiYgV3ay7O/Xb6m2S7sq6JFaQGsvatuoqBkh9/0dI2oLU\nR39nRDzXqGJEvADcBHwk6046jqxbKPNpUmPcKumPkk7sJv4rgIMlbUva8300Iv6Yez8nSfpD1m2x\nHHgd3X/2ANuSGsv8tnkqXyHr3ngs20bLgK2aWG/Na+rW9xSwGfCPrsCIaOp/sI+f17bZ63X1Wfak\nN9+v7v5nbgbeqHSm1iHAcxHxQB9j2uQ4EZSv/vKvF5H2BHeKiK2BL5P24oq0mNSwAyBJwORu6p9I\n+t/5o6S/Ab8hvY9aI7gQeG2D5y0EJtb6mOu8SOraqHl1gzr12+paUiM9NSLGApfQsa26ioFIZ9vM\nBT5A2gu8slG9nMtJCeM9pC6DW3LrWhwRJ0fEdsBpwMXKjb3Uve6TwO9IyeQEcoPEknYkHVl8HJgQ\nEeOAx+j5s38W2EBqxGr+cVqppANJXX0fJB2FjCcd4dTW29Plh58Bdqhb91rSHnFv9eXzejZ7vUZl\nnf5nsv76CXV1evP96u5/5qUs9tpn19P/zKDiRLDpGQOsAF6U9HrgYwPwmj8j7dG/P/synUlujy9P\n0pbAh4B/BfbMTWeRBh2Hk7qGTpZ0YDbYOEXSLhGxELgdmCVpnKSR6jil8g/AHtlg3RbAV5qIewzw\nfESslvRWUmNdcxVwiKQPZoOrEyW9MVd+BfAF0l73T3t4nTtJjc4FwI8iYl1uexwtqZY0l5Manpe7\nWdflpO27D+lIqmZ09tz2tFqdksXWrSyWnwD/KWmL7KgsP7g9htR1tIR05HIO6Yig5llgWpb8G7kG\n+JSkaZLGAF8DromIDT3F1kCvP6+IeBm4DPiOpFcr/YZi32yA9zFgjKT3ZPNfyd5jTzF09f2aDWwv\naWY2GL21pL1z5VeQulHfl8U7ZDgRbHo+TdqzXkXae7mu++qvXEQ8C3wY+BawlLRX9CCpb7beUVls\nV0XE32oT8H3SYNzBEfFb4BTgfNKX7k469liPz/7OJzVCp2cxPAJ8HbiLNJh7TxOhfxz4RnZGyL8D\n1+fe019Ig4SfJ53i+gDwhtxzbyINFt4YEX/v7kWyrrIrSXvGV9QV7wPMUTqT6cfAadH9+f03kLoi\nbst3R0XEw6QByPtJR2i7AL/vLq6cj5P29J8lJeFLc2W3kJLvE6RxqpXZ+muuI3W9PC/p/gbr/n5W\n59ekwe5VpETWF339vM4inZAwNyv7OqCIWEb6/7mcNAD+PJ27Pxvp8vuVdVkeTDp6epb0P/rO3HPv\nIY0P/D4iuus6HXSUDX6Y/UO2V/8MadDv12XHU4RsD/gvpEHRu0oOxwYJSfeQTlq4rOxY+pOPCAwA\nSYdk3TWbk87gWEfaOx2qjiYd8dxddiA2OGTdWbuTjuqGlKHxYwjrD+8g9VmPAOYBR0ZEo66hQU/S\nvcAM4LjwIbE1QdLVpLGB0yPixbLj6W/uGjIzqzh3DZmZVVxhXUOSfggcRvrhxe4NygWcB7yX9COU\nk5r5gcbEiRNj2rRp/RytmdnQNnfu3CUR0fC08CLHCC4j/YS8/nS7mkNJ/bQzSKfgXZD97da0adNo\nbW3tpxDNzKpB0lNdlRXWNRQR95DO6+3KEcAVkdwHjJO0XVHxmJlZY2WOEUym83VA2ujisgaSTpXU\nKqm1vb0vv2w3M7OuDIrB4oi4OCJaIqJl0qSGXVxmZtZHZf6OYBGdL5Q1JVtmZmbdWLduHW1tbaxe\nvXqjslGjRjFlyhRGjuzpsksdykwEs4GZSvdr3QdYERGLe3iOmVnltbW1MWbMGKZNm0b+eoERwdKl\nS2lra2P69IYXwW2oyNNHrwEOIF12uI3clQEj4kLSxbDeCywgnT760aJiMTMbSlavXr1REgCQxIQJ\nE+jtWGphiSAiju2hPEjXbzczs17q6srhXV9RvGu+1pCZWVciYP36junll/v2uL+ed9hh8Ja39Pvb\ndCIws/63YQOsXdt4Wreu67JGddetSw1hs497U7en573c3T2GSrDddk4EZpbZsAHWrEnT2rUdj/tr\nvjdTo4a9yAZ02DAYMQJGjuz428zjUaNg9OjeP6/2d/jw9HjEiMaPeypv5nF35cOGQd3AcKNuoL5c\nSNSJwKwIGzbAiy/CqlWwcmXHVD9fv+yFF2D16p4b6/5saCXYfPM0bbbZxn/z09Zbb7wsP40c2X15\nb+vUGuV8gzxsUPz8qVCjRo1i6dKlTJgwoeFZQ6NGjerV+pwIzPLWrOm60e5No75qVepf7snmm8OY\nMamB3XrrtMe65ZYwfnxH45xvmLuafyV1RozotKdpm74pU6bQ1tbW8Oyg2u8IesOJwIamiLR3vWRJ\nx9Te3v38ypVpz7snUkfDXWvEx46FqVM7N+r58kbzY8akxtisl0aOHNmr3wn0xInABoe1azs32s00\n7Gu6uMHaiBEwcWLH9IY3wIQJMG5ccw35Vlt5D9qGFCcCG3gRsHx5arjzjXd3DfvKlV2vb/z4jkZ9\n++3hzW/u3NBPmtR5fuxYN+RmOU4E9spt2NC5YX/uuY7HjZYtWZLONGlk1KjUcNca75122rghz8+/\n6lVpANHM+syJwDa2YQMsW9Zzg16bX7Kk67NYtt66o2HfYYd0DnRtvn6aODENlJrZgHIiqJIIWLwY\nnngiTYsWNW7kly7tumEfOzY12ttsAzvuCPvs0zHfqHH3YKjZJs+JYKiJSHvotcZ+/vyOx088kc5t\nzxs/vqPRnjED9t1348a81shPnJhONzSzIcWJYLBavrxxYz9/PqxY0VFv+HCYPj018vvvn/7uvHP6\nO2WK+9fNzIlgk/bCC7BgwcZ79fPnp73+GimdLTNjBhx3XPpbm6ZPd2NvZt1yIijb3/8Of/7zxg39\nE0+k/vy817wm7c0feWRHQ7/zzqmvvpc/KTczq3EiGEjr18NPfwp33NHR2C9c2PlSBNtskxr497yn\nczfOTjulHzKZmfUzJ4KB8PzzcMklMGsWPP10OvNml11gv/06GvraNHZs2dGaWcU4ERRp3jw4/3y4\n8srUBXTggWn+sMPSIK6Z2SbAiaC/bdgAt9wC550Ht9+e+u6POw7OOAP22KPs6MzMNuJE0F9WroRL\nL4XvfjcN/k6eDF//OpxySjr/3sxsE+VE8EotWJAa/0svTdegf/vb4Wtfg6OO8mmbZjYoOBH0RUTq\n9jn/fPj5z9NljT/84dT9U8D9RM3MiuRE0BsvvZQGfs8/Hx55JJ3q+aUvwb/9W7qptJnZIORE0Iyn\nnoLvfQ++//10Vc699oLLL09HAb6ompkNck4EXYmAe+9NZ//cfHO6jMORR8KZZ6YLs/nGJmY2RDgR\n1Fu9Gq69NnX/PPhgujrnZz8Ln/hEup6PmdkQ40RQs3gxXHABXHhhuib/brvBRRfB8cf7ZilmNqQ5\nEdx/f+r+uf76dDOWww5LZ/8cdJC7f8ysEqqZCNatg5tuSgngvvtgzBg47TSYOTNd3M3MrEKqlQja\n2+Hii9MZQM88kxr9886Dk05K99Y1M6ug6iSCCy6As86CNWvg4INTQjj0UBg2rOzIzMxKVZ1EsPvu\nac//jDNg113LjsbMbJNR6O6wpEMkPS5pgaSzG5TvIOkOSQ9LukvSlMKC2W+/dEaQk4CZWSeFJQJJ\nw4FZwKHArsCxkupb4W8CV0TEHsC5wDeKisfMzBor8ohgb2BBRDwZEWuBa4Ej6ursCvwqe3xng3Iz\nMytYkYlgMrAwN9+WLcv7A3BU9vhIYIykCfUrknSqpFZJre3t7YUEa2ZWVWWfMvMZ4J2SHgTeCSwC\nXq6vFBEXR0RLRLRMmjRpoGM0MxvSijxraBEwNTc/JVv2DxHxDNkRgaTRwAcjYnmBMZmZWZ0ijwjm\nADMkTZe0GXAMMDtfQdJESbUYvgD8sMB4zMysgcISQUSsB2YCtwGPAtdHxDxJ50o6PKt2APC4pPnA\ntsDXiorHzMwaU0SUHUOvtLS0RGtra9lhmJkNKpLmRkRLo7KyB4vNzKxkTgRmZhXnRGBmVnFOBGZm\nFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXn\nRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50Rg\nZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhVXaCKQdIikxyUtkHR2g/Lt\nJd0p6UFJD0t6b5HxmJnZxgpLBJKGA7OAQ4FdgWMl7VpX7YvA9RHxJuAY4HtFxWNmZo0VeUSwN7Ag\nIp6MiLXAtcARdXUC2Dp7PBZ4psB4zMysgSITwWRgYW6+LVuWdw5wvKQ24Bbg9EYrknSqpFZJre3t\n7UXEamZWWWUPFh8LXBYRU4D3AldK2iimiLg4IloiomXSpEkDHqSZ2VBWZCJYBEzNzU/JluX9K3A9\nQET8DhgFTCwwJjMzq1NkIpgDzJA0XdJmpMHg2XV1ngYOApD0elIicN+PmdkAaioRSPqxpPc16rbp\nSkSsB2YCtwGPks4OmifpXEmHZ9U+DZwi6Q/ANcBJERG9ewtmZvZKqJl2V9K7gY8CbwVuAC6NiMcL\njq2hlpaWaG1tLeOlzcwGLUlzI6KlUVlTe/gRcXtEHAfsBfwVuF3SbyV9VNLI/gvVzMwGWtNdPZIm\nACcBJwMPAueREsMvC4nMzMwGxIhmKkm6GdgFuBJ4f0Qszoquk+R+GjOzQaypRACcHxF3Niroqs/J\nzMwGh2a7hnaVNK42I2m8pE8UFJOZmQ2gZhPBKRGxvDYTEcuAU4oJyczMBlKziWC4JNVmsiuLblZM\nSGZmNpCaHSO4lTQwfFE2/7FsmZmZDXLNJoLPkxr/j2fzvwQuKSQiMzMbUE0lgojYAFyQTWZmNoQ0\n+zuCGcA3SHcaG1VbHhE7FhSXmZkNkGYHiy8lHQ2sBw4ErgCuKiooMzMbOM0mgi0i4g7SReqeiohz\ngPcVF5aZmQ2UZgeL12SXoH5C0kzSDWZGFxeWmZkNlGaPCM4EtgTOAN4MHA+cWFRQZmY2cHo8Ish+\nPPbhiPgM8ALpvgRmZjZE9HhEEBEvA+8YgFjMzKwEzY4RPChpNunuZC/WFkbEjwuJyszMBkyziWAU\nsBR4V25ZAE4EZmaDXLO/LPa4gJnZENXsL4svJR0BdBIR/9LvEZmZ2YBqtmvoZ7nHo4AjgWf6Pxwz\nMxtozXYN3ZSfl3QNcG8hEZmZ2YBq9gdl9WYA2/RnIGZmVo5mxwhW0XmM4G+kexSYmdkg12zX0Jii\nAzEzs3I01TUk6UhJY3Pz4yR9oLiwzMxsoDQ7RvCViFhRm4mI5cBXignJzMwGUrOJoFG9Zk89NTOz\nTViziaBV0rckvTabvgXMLTIwMzMbGM0mgtOBtcB1wLXAauC0ooIyM7OB0+xZQy8CZxcci5mZlaDZ\ns4Z+KWlcbn68pNuaeN4hkh6XtEDSRolE0rclPZRN8yUt7134Zmb2SjU74DsxO1MIgIhYJqnbXxZn\ndzabBRwMtAFzJM2OiEdy6zkrV/904E29Cd7MzF65ZscINkjavjYjaRoNrkZaZ29gQUQ8GRFrSWML\nR3RT/1jgmibjMTOzftLsEcF/APdKuhsQsB9wag/PmQwszM23Afs0qihpB2A68Ksuyk+tvd7222/f\nqIqZmfVRU0cEEXEr0AI8Ttpr/zTw936M4xjgxuz+yI1e/+KIaImIlkmTJvXjy5qZWbMXnTsZOBOY\nAjwEvBX4HZ1vXVlvETA1Nz8lW9bIMfh0VDOzUjQ7RnAm8BbgqYg4kDSo29MZPnOAGZKmS9qM1NjP\nrq8k6XXAeFJiMTOzAdZsIlgdEasBJG0eEY8Bu3T3hIhYD8wEbgMeBa6PiHmSzpV0eK7qMcC1EdHT\n4LOZmRWg2cHitux3BD8BfilpGfBUT0+KiFuAW+qWfblu/pwmYzAzswI0+8viI7OH50i6ExgL3FpY\nVGZmNmB6fQXRiLi7iEDMzKwcfb1nsZmZDRFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBm\nVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZx\nTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4E\nZmYV50RgZlZxTgRmZhVXaCKQdIikxyUtkHR2F3WOlvSIpHmSflRkPGZmtrERRa1Y0nBgFnAw0AbM\nkTQ7Ih7J1ZkBfAHYNyKWSdqmqHjMzKyxIo8I9gYWRMSTEbEWuBY4oq7OKcCsiFgGEBHPFRiPmZk1\nUGQimAwszM23ZcvydgZ2lvQbSfdJOqTRiiSdKqlVUmt7e3tB4ZqZVVPZg8UjgBnAAcCxwPcljauv\nFBEXR0RLRLRMmjRpgEM0MxvaikwEi4Cpufkp2bK8NmB2RKyLiL8A80mJwczMBkiRiWAOMEPSdEmb\nAccAs+vq/IR0NICkiaSuoicLjMnMzOoUlggiYj0wE7gNeBS4PiLmSTpX0uFZtduApZIeAe4EPhsR\nS4uKyczMNqaIKDuGXmlpaYnW1taywzAzG1QkzY2IlkZlZQ8Wm5lZyZwIzMwqzonAzKzinAjMzCrO\nicDMrOKcCMzMKs6JwMys4pwIzMwqzonAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4pwIzMwqzonA\nzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4pwIzMwqzonAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys\n4pwIzMwqzonAzKzinAjMzCrOicDMrOKcCMzMKs6JwMys4pwIzMwqrtBEIOkQSY9LWiDp7AblJ0lq\nl/RQNp1cZDxmZraxEUWtWNJwYBZwMNAGzJE0OyIeqat6XUTMLCoOMzPrXmGJANgbWBARTwJIuhY4\nAqhPBAPik5+Ehx4q45XNzPrHnnvCd77T/+stsmtoMrAwN9+WLav3QUkPS7pR0tRGK5J0qqRWSa3t\n7e1FxGpmVllFHhE043+AayJijaSPAZcD76qvFBEXAxcDtLS0RF9eqIgsamY2FBR5RLAIyO/hT8mW\n/UNELI2INdnsJcCbC4zHzMwaKDIRzAFmSJouaTPgGGB2voKk7XKzhwOPFhiPmZk1UFjXUESslzQT\nuA0YDvwwIuZJOhdojYjZwBmSDgfWA88DJxUVj5mZNaaIPnW5l6alpSVaW1vLDsPMbFCRNDciWhqV\n+ZfFZmYV50RgZlZxTgRmZhXnRGBmVnGDbrBYUjvwVB+fPhFY0o/hDHbeHp15e3TwtuhsKGyPHSJi\nUqOCQZcIXglJrV2NmleRt0dn3h4dvC06G+rbw11DZmYV50RgZlZxVUsEF5cdwCbG26Mzb48O3had\nDentUakxAjMz21jVjgjMzKyOE4GZWcVVJhFIOkTS45IWSDq77HjKImmqpDslPSJpnqQzy45pUyBp\nuKQHJf2s7FjKJmlcdsfAxyQ9KultZcdUFklnZd+TP0m6RtKosmMqQiUSgaThwCzgUGBX4FhJu5Yb\nVWnWA5+OiF2BtwKnVXhb5J2J74dRcx5wa0S8DngjFd0ukiYDZwAtEbE76XL6x5QbVTEqkQiAvYEF\nEfFkRKwFrgWOKDmmUkTE4oh4IHu8ivQlb3Qv6cqQNAV4H+kueZUmaSywP/ADgIhYGxHLy42qVCOA\nLSSNALYEnik5nkJUJRFMBhbm5tuoeOMHIGka8Cbg9+VGUrrvAJ8DNpQdyCZgOtAOXJp1lV0iaauy\ngypDRCwCvgk8DSwGVkTEL8qNqhhVSQRWR9Jo4CbgkxGxsux4yiLpMOC5iJhbdiybiBHAXsAFEfEm\n4EWgkmNqksaTeg6mA68BtpJ0fLlRFaMqiWARMDU3PyVbVkmSRpKSwNUR8eOy4ynZvsDhkv5K6jJ8\nl6Sryg2pVG1AW0TUjhJvJCWGKno38JeIaI+IdcCPgbeXHFMhqpII5gAzJE2XtBlpwGd2yTGVQpJI\n/b+PRsS3yo6nbBHxhYiYEhHTSP8Xv4qIIbnX14yI+BuwUNIu2aKDgEdKDKlMTwNvlbRl9r05iCE6\ncF7Yzes3JRGxXtJM4DbSyP8PI2JeyWGVZV/gBOCPkh7Klv17RNxSYky2aTkduDrbaXoS+GjJ8ZQi\nIn4v6UbgAdLZdg8yRC814UtMmJlVXFW6hszMrAtOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmBZN0\ngK9qapsyJwIzs4pzIjDLSDpe0v2SHpJ0UXaPghckfTu7Jv0dkiZldfeUdJ+khyXdnF2XBkk7Sbpd\n0h8kPSDptdnqR+eu8X919ktVJP1Xdm+IhyV9s6S3bhXnRGAGSHo98GFg34jYE3gZOA7YCmiNiN2A\nu4GvZE+5Avh8ROwB/DG3/GpgVkS8kXRdmsXZ8jcBnyTdD2NHYF9JE4Ajgd2y9Xy12Hdp1pgTgVly\nEPBmYE526Y2DSA32BuC6rM5VwDuya/aPi4i7s+WXA/tLGgNMjoibASJidUS8lNW5PyLaImID8BAw\nDVgBrAZ+IOkooFbXbEA5EZglAi6PiD2zaZeIOKdBvb5ek2VN7vHLwIiIWE+6adKNwGHArX1ct9kr\n4kRgltwBfEjSNgCSXiVpB9J35ENZnX8G7o2IFcAySftly08A7s7u+NYm6QPZOjaXtGVXL5jdE2Js\ndsG/s0i3hTQbcJW4+qhZTyLiEUlfBH4haRiwDjiNdGOWvbOy50jjCAAnAhdmDX3+Cp0nABdJOjdb\nx//q5mXHAD/Nbogu4FP9/LbMmuKrj5p1Q9ILETG67DjMiuSuITOzivMRgZlZxfmIwMys4pwIzMwq\nzonAzKzinAjMzCrOicDMrOL+P/Tpzi5zHriKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5v_P_RX7juf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#custom model from kaggle\n",
        "def CNNbuild(inputShape , classes):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    #inputShape = (height, width, channels)\n",
        "    #chanDim = -1\n",
        "    \n",
        "    #if K.image_data_format() == 'channels_first':\n",
        "        #inputShape = (channels, height, width)\n",
        "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "    model.add(BatchNormalization(axis = -1))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "    model.add(BatchNormalization(axis = -1))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "    model.add(BatchNormalization(axis = -1))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    \n",
        "    model.add(Dense(512, activation = 'relu'))\n",
        "    model.add(BatchNormalization(axis = -1))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(classes, activation = 'sigmoid'))\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzWy6KsG8XHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_model = CNNbuild(inputShape=(224,224,3),classes = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgoNo01R8vJF",
        "colab_type": "code",
        "outputId": "633d611b-d0c6-4260-84a7-769d381a5709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "custom_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 111, 111, 32)      128       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 109, 109, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 54, 54, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 54, 54, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 54, 54, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 52, 52, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 21632)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               11076096  \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 11,098,433\n",
            "Trainable params: 11,097,217\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoPmTOmt9yd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_model.compile(optimizer='adam',loss = 'binary_crossentropy',metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwUBgjXZ99pm",
        "colab_type": "code",
        "outputId": "320fbd65-a295-4727-d902-19d88766326f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history = custom_model.fit_generator(\n",
        "    train_gen,\n",
        "    epochs = 10,\n",
        "    validation_data = val_gen,\n",
        "    verbose = 1,\n",
        "    #callbacks = [callback]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.4790 - acc: 0.8012Epoch 1/10\n",
            "689/689 [==============================] - 262s 380ms/step - loss: 0.4788 - acc: 0.8013 - val_loss: 0.6009 - val_acc: 0.8015\n",
            "Epoch 2/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.9076Epoch 1/10\n",
            "689/689 [==============================] - 256s 372ms/step - loss: 0.2631 - acc: 0.9074 - val_loss: 0.2278 - val_acc: 0.9309\n",
            "Epoch 3/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9146Epoch 1/10\n",
            "689/689 [==============================] - 258s 374ms/step - loss: 0.2459 - acc: 0.9147 - val_loss: 0.1964 - val_acc: 0.9316\n",
            "Epoch 4/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9242Epoch 1/10\n",
            "689/689 [==============================] - 256s 371ms/step - loss: 0.2288 - acc: 0.9242 - val_loss: 0.2270 - val_acc: 0.9221\n",
            "Epoch 5/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9215Epoch 1/10\n",
            "689/689 [==============================] - 254s 368ms/step - loss: 0.2304 - acc: 0.9216 - val_loss: 0.2140 - val_acc: 0.9307\n",
            "Epoch 6/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9266Epoch 1/10\n",
            "689/689 [==============================] - 254s 369ms/step - loss: 0.2181 - acc: 0.9265 - val_loss: 0.3378 - val_acc: 0.8528\n",
            "Epoch 7/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9299Epoch 1/10\n",
            "689/689 [==============================] - 255s 370ms/step - loss: 0.2080 - acc: 0.9300 - val_loss: 0.2025 - val_acc: 0.9289\n",
            "Epoch 8/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9379Epoch 1/10\n",
            "689/689 [==============================] - 257s 373ms/step - loss: 0.1877 - acc: 0.9379 - val_loss: 0.1798 - val_acc: 0.9354\n",
            "Epoch 9/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9421Epoch 1/10\n",
            "689/689 [==============================] - 255s 370ms/step - loss: 0.1731 - acc: 0.9421 - val_loss: 0.1746 - val_acc: 0.9515\n",
            "Epoch 10/10\n",
            "688/689 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9473Epoch 1/10\n",
            "689/689 [==============================] - 255s 371ms/step - loss: 0.1620 - acc: 0.9472 - val_loss: 0.1774 - val_acc: 0.9432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDoAz4kP-fGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot the model\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs,acc,'r')\n",
        "plt.plot(epochs,val_acc,'b')\n",
        "plt.title('Training Accuracy Vs Validation accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'r')\n",
        "plt.plot(epochs,val_loss,'b')\n",
        "plt.title('Training Loss Vs Validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}